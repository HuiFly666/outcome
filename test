import time
from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, balanced_accuracy_score, accuracy_score

def test(model, test_loader, device, metrics_history):
    model.eval()  # 设置模型为评估模式

    y_true = []  # 存储真实标签
    y_pred = []  # 存储预测标签
    total_loss = 0  # 累计测试损失
    criterion = torch.nn.BCELoss()  # 二元交叉熵损失

    # 开始记录测试时间
    start_time = time.time()

    with torch.no_grad():  # 不需要计算梯度
        for data, targets in test_loader:
            data, targets = data.to(device), targets.to(device).float()

            # 初始化隐藏状态
            hidden = model.init_hidden(data.size(0))

            # 前向传播
            outputs, hidden = model(data, hidden)

            # 计算损失
            loss = criterion(outputs, targets.unsqueeze(1))  # 确保targets的形状与outputs一致
            total_loss += loss.item()  # 累加损失

            # 将输出转换为 0 或 1
            predicted = (outputs >= 0.5).float()  # 阈值 0.5

            # 将结果保存到列表中，转为CPU的numpy格式
            y_true.extend(targets.cpu().numpy())
            y_pred.extend(predicted.cpu().numpy())

    # 计算测试时间
    test_time = time.time() - start_time

    # 计算各种指标
    accuracy = accuracy_score(y_true, y_pred)
    avg_loss = total_loss / len(test_loader)
    precision = precision_score(y_true, y_pred)
    recall = recall_score(y_true, y_pred)
    f1 = f1_score(y_true, y_pred)
    roc_auc = roc_auc_score(y_true, y_pred)
    conf_matrix = confusion_matrix(y_true, y_pred)
    balanced_acc = balanced_accuracy_score(y_true, y_pred)
   

    # 将指标保存到 metrics_history 中
    metrics_history['test_accuracy'].append(accuracy)
    metrics_history['test_loss'].append(avg_loss)  # 保存平均损失
    metrics_history['precision'].append(precision)
    metrics_history['recall'].append(recall)
    metrics_history['f1'].append(f1)
    metrics_history['roc_auc'].append(roc_auc)
    metrics_history['balanced_accuracy'].append(balanced_acc)
    

    # 输出结果
    print(f'Average_Loss_test: {avg_loss:.4f}')
    print(f'Accuracy_test: {accuracy:.4f}')
    print(f'Precision: {precision:.4f}')
    print(f'Recall: {recall:.4f}')
    print(f'F1 Score: {f1:.4f}')
    print(f'ROC AUC: {roc_auc:.4f}')
    print(f'Confusion Matrix:\n{conf_matrix}')
    print(f'Balanced Accuracy: {balanced_acc:.4f}')
    print(f'Test Time: {test_time:.2f} seconds')

    return test_time  # 返回测试时间
